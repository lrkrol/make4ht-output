<!DOCTYPE html> 
<html lang='en-US' xml:lang='en-US'> 
<head><title></title> 
<meta charset='utf-8' /> 
<meta content='TeX4ht (https://tug.org/tex4ht/)' name='generator' /> 
<meta content='width=device-width,initial-scale=1' name='viewport' /> 
<link href='main.css' rel='stylesheet' type='text/css' /> 
<meta content='main.tex' name='src' /> 
</head><body>
<!-- l. 62 --><p class='noindent'>

</p><!-- l. 62 --><p class='indent'>

</p>
<div class='center'>
<!-- l. 62 --><p class='noindent'>
</p>
<div class='tabular'> <table class='tabular' id='TBL-1'><colgroup id='TBL-1-1g'><col id='TBL-1-1' /></colgroup><tr id='TBL-1-1-' style='vertical-align:baseline;'><td class='td11' id='TBL-1-1-1' style='white-space:nowrap; text-align:center;'>                              <span class='cmr-12'>Laurens R. Krol</span><sup class='textsuperscript'><span class='cmr-9'>1,*</span></sup> <span class='cmr-12'>and Thorsten O. Zander</span><sup class='textsuperscript'><span class='cmr-9'>2</span></sup>                                                             </td>
</tr><tr class='vspace' style='font-size:10.00002pt'><td> </td></tr><tr id='TBL-1-2-' style='vertical-align:baseline;'><td class='td11' id='TBL-1-2-1' style='white-space:nowrap; text-align:center;'><sup class='textsuperscript'><span class='cmr-9'>1</span></sup><span class='cmr-12'>Neuroadaptive Human-Computer Interaction, Brandenburg University of Technology, Cottbus-Senftenberg, Germany</span></td>
</tr><tr id='TBL-1-3-' style='vertical-align:baseline;'><td class='td11' id='TBL-1-3-1' style='white-space:nowrap; text-align:center;'>                         <sup class='textsuperscript'><span class='cmr-9'>2</span></sup><span class='cmr-12'>Zander Laboratories B.V., Amsterdam, The Netherlands                                        </span></td>
</tr><tr id='TBL-1-4-' style='vertical-align:baseline;'><td class='td11' id='TBL-1-4-1' style='white-space:nowrap; text-align:center;'>                                  <sup class='textsuperscript'><span class='cmr-9'>*</span></sup><span class='cmr-12'>Correspondence: </span><span class='cmtt-12'>lrkrol@gmail.com                                  </span></td></tr></table>
</div>
</div>
   <section class='abstract' role='doc-abstract'> 
<h3 class='abstracttitle'>
<span class='cmbx-9'>Abstract</span>
</h3>
</section>
   <h3 class='likesectionHead' id=''><a id='x1-1000'></a>1.1.3</h3>
<!-- l. 72 --><p class='noindent'>A brain-computer interface (BCI) is a neurotechnological system that allows human mental states to
be directly accessed by a computer. To that end, the BCI system reads human brain activity, most
commonly using electroencephalography (EEG), applies a number of signal processing and feature
extraction steps, and employs machine learning algorithms in order to classify the resulting features as
being indicative of certain mental states. This was first demonstrated in the 1970s <span class='cite'>(?, ?)</span> has been
under continuous development ever since, primarily in medical contexts. Here, BCI systems are
envisioned to, for example, enable paralysed or otherwise motor-impaired patients to regain
independence by replacing natural neural pathways with BCIs <span class='cite'>(?, ?)</span>. However, more than that can be
done with technology that has direct access to human mental states. <span class='cite'>? (?)</span> in particular introduced the
concept of <span class='cmti-10'>passive </span>BCIs, where technology uses arbitrary, naturally occurring mental states as
input, as opposed to those <span class='cmti-10'>active </span>BCIs that are used for intentional, direct communication
and control <span class='cite'>(?, ?)</span>. This latter category simply replaces existing means of control with a
BCI. The former, however, enables new forms of <span class='cmti-10'>implicit </span>human-computer interaction,
through which technology can automatically adapt to its human user, without this user
actively communicating anything, or even being aware of any communication taking place <span class='cite'>(?,
?)</span>.
</p><!-- l. 76 --><p class='noindent'>
</p>
   <h3 class='likesectionHead' id='1'><a id='x1-2000'></a>1.1.4</h3>
<!-- l. 78 --><p class='noindent'>A number of studies utilising BCI systems in automotive contexts have relied on active BCIs,
thus replacing the driver’s manual control over certain systems with intentional BCI-based
control.

</p><!-- l. 80 --><p class='indent'>   For example, ...
</p><!-- l. 83 --><p class='indent'>   Aside from that, many studies have used EEG and other modalities to investigate states like fatigue
and workload during driving <span class='cite'>(e.g., ?, ?, ?)</span>. These and other findings have been used to inform
automotive adaptation using passive BCI. For example, <span class='cite'>? (?)</span> demonstrated how a passive BCI system
can detect mental load during driving and automatically adjust secondary tasks to better
suit the driver’s current state. <span class='cite'>? (?)</span> demonstrated the feasibility of using EEG activity
to passively detect emergency braking intention. <span class='cite'>? (?)</span> developed a real-time, pBCI-based
drowsiness detector to allow accident prevention measures to be taken when drivers are
detected to be incapable of attentive driving. See i.a. <span class='cite'>? (?)</span> for a further discussion of the
literature.
</p><!-- l. 87 --><p class='indent'>   In the current context, a final mention is made of an exploratory study attempting to extract
emotional responses to different behaviour patterns of self-driving cars <span class='cite'>(?, ?)</span>. This exploratory, <span class='cmmi-10'>n </span>= 1
study used simple measures from a single electrode with correspondingly inconclusive results, but noted
parietal alpha/beta power ratio as a candidate indicator.
</p><!-- l. 90 --><p class='noindent'>
</p>
   <h3 class='likesectionHead' id='eigene-vorarbeiten'><a id='x1-3000'></a>Eigene Vorarbeiten</h3>
<!-- l. 92 --><p class='noindent'>Approximately a decade ago, the concept of passive BCI was formally introduced by one of the
consortial partners <span class='cite'>(?, ?)</span>. Since then, various mental states have been investigated by this group for
use with passive BCI, including loss of control <span class='cite'>()</span>, workload <span class='cite'>(?, ?)</span>, predictive coding and
error-related perceptions <span class='cite'>(?, ?)</span>, and subjective interpretations of positive/negative behaviour <span class='cite'>(?,
?)</span>.
</p><!-- l. 94 --><p class='indent'>   In-vehicle physiological recordings are prone to both environmental and internal artefacts, due to
the car’s electronic equipment and the natural movement of the participant. We have previously
investigated the art and nature of these automotive artefact sources as well as EEG hardware
susceptibility to typical in-vehicle human movements <span class='cite'>(?, ?)</span>. Subsequently, in a separate study, we
investigated ability of state-of-the-art signal processing algorithms to clean data recorded during real
driving of 15 participants <span class='cite'>(?, ?)</span>. Results show that, taking the identified artefactual sources into
account, neural correlates can be recovered to allow pBCI classification. Furthermore, in the context of
adaptive cruise control (ACC) behaviour, we have found that, aside from neurophysiological correlates,
heart rate and blink duration may serve as an indicator of ACC-related driving experience <span class='cite'>(?,
?)</span>.
</p><!-- l. 96 --><p class='indent'>   Aside from cars, passive BCI systems have also been applied in full-body flight simulators. In
particular, it has been demonstrated that passive BCI can be used to detect pilot perceptions of
cockpit alerts in order to inform a cognitive model <span class='cite'>(?, ?)</span>. The passive BCI system used for this was
context-independent, being trained on an abstract task and subsequently transferred onto realistic data
recorded in the flight simulator <span class='cite'>(?, ?)</span>. As such, this approach is not limited to flight, but can be used in
cars as well.
</p>
    
</body> 
</html>